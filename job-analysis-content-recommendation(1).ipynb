{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Аналитический рекомендатель по содержанию вакансий \n\nРазработаем механизм рекомендаций с использованием NLTK, который поможет соискателям выбирать предпочтительную работу на основе заявок.\n\nВ процессе узнаем, как лемматизация, стемминг и векторизация используются для обработки данных и получения лучшего результата. \n\nПоехали!"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"#Импортируем библиотеки\n\nimport pandas as pd\nimport numpy as np\n\n#Загрузим файл\n\nfinal_jobs = pd.read_csv(\"../input/Combined_Jobs_Final.csv\")\n\n#Посмотрим первые 5 строк набора данных\n\nfinal_jobs.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Список всех столбцов, которые присутствуют в наборе данных\n\nlist(final_jobs) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nsns.heatmap(final_jobs.isnull(), cbar=False); ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(final_jobs.shape)\nfinal_jobs.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Из приведенного выше списка мы видим, что существует много значений NaN. Выполним очистку данных для каждого столбца. "},{"metadata":{},"cell_type":"markdown","source":"## Объединим столбцы в рабочий корпус\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Возьмём только необходимые для анализа столбцы\ncols = list(['Job.ID']+['Slug']+['Title']+['Position']+ ['Company']+['City']+['Employment.Type']+['Education.Required']+['Job.Description'])\nfinal_jobs =final_jobs[cols]\nfinal_jobs.columns = ['Job.ID','Slug', 'Title', 'Position', 'Company','City', 'Empl_type','Edu_req','Job_Description']\nfinal_jobs.head() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Проверим нулевые значения\nfinal_jobs.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Посмотрим пропущенные значения в колонке Город\nnan_city = final_jobs[pd.isnull(final_jobs['City'])]\nprint(nan_city.shape)\nnan_city.head()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"nan_city.groupby(['Company'])['City'].count() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Видно, что всего 9 городов компаний имеют значение NaN, поэтому вручную добавим их головные офисы, покопавшись в сети. \n"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"#Заменим пропущенные значения локацией штаб-квартир\n\nfinal_jobs['Company'] = final_jobs['Company'].replace(['Genesis Health Systems'], 'Genesis Health System')\n\nfinal_jobs.loc[final_jobs.Company == 'CHI Payment Systems', 'City'] = 'Illinois'\nfinal_jobs.loc[final_jobs.Company == 'Academic Year In America', 'City'] = 'Stamford'\nfinal_jobs.loc[final_jobs.Company == 'CBS Healthcare Services and Staffing ', 'City'] = 'Urbandale'\nfinal_jobs.loc[final_jobs.Company == 'Driveline Retail', 'City'] = 'Coppell'\nfinal_jobs.loc[final_jobs.Company == 'Educational Testing Services', 'City'] = 'New Jersey'\nfinal_jobs.loc[final_jobs.Company == 'Genesis Health System', 'City'] = 'Davennport'\nfinal_jobs.loc[final_jobs.Company == 'Home Instead Senior Care', 'City'] = 'Nebraska'\nfinal_jobs.loc[final_jobs.Company == 'St. Francis Hospital', 'City'] = 'New York'\nfinal_jobs.loc[final_jobs.Company == 'Volvo Group', 'City'] = 'Washington'\nfinal_jobs.loc[final_jobs.Company == 'CBS Healthcare Services and Staffing', 'City'] = 'Urbandale'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_jobs.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"#Тип занятости NA от Uber, поэтому я предполагаю, что это неполный или полный рабочий день. \n\nnan_emp_type = final_jobs[pd.isnull(final_jobs['Empl_type'])]\nprint(nan_emp_type)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Заменим NA значения на \"Неполный / Полный рабочий день\"\nfinal_jobs['Empl_type'] = final_jobs['Empl_type'].fillna('Full-Time/Part-Time')\nfinal_jobs.groupby(['Empl_type'])['Company'].count()\nlist(final_jobs)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#   Объединение "},{"metadata":{},"cell_type":"markdown","source":"#### Объединение столбцов position, company, city, empl_type и jobDesc"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"final_jobs[\"pos_com_city_empType_jobDesc\"] = final_jobs[\"Position\"].map(str) + \" \" + final_jobs[\"Company\"] +\" \"+ final_jobs[\"City\"]+ \" \"+final_jobs['Empl_type']+\" \"+final_jobs['Job_Description']\nfinal_jobs.pos_com_city_empType_jobDesc.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Удалим ненужные символы между словами, разделенными пробелами во всех столбцах, \n#чтобы сделать данные эффективными \n\nfinal_jobs['pos_com_city_empType_jobDesc'] = final_jobs['pos_com_city_empType_jobDesc'].str.replace('[^a-zA-Z \\n\\.]',\" \")\nfinal_jobs.pos_com_city_empType_jobDesc.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Преобразуем все символы в нижний регистр \n\nfinal_jobs['pos_com_city_empType_jobDesc'] = final_jobs['pos_com_city_empType_jobDesc'].str.lower() \nfinal_jobs.pos_com_city_empType_jobDesc.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_all = final_jobs[['Job.ID', 'pos_com_city_empType_jobDesc']]\nfinal_all = final_all.fillna(\" \")\n\nfinal_all.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"А вот и важная концепция **Стоп-слов**. \nСтоп-слова — это слова естественного языка, которые имеют очень мало значения, такие как «and», «the», «a», «an» и подобные.\nИспользуем NLP, где NLTK (Natural Language Toolkit) используется для игнорирования слов.\nТекст может содержать такие стоп-слова, как «the», «is», «are». Стоп-слова можно отфильтровать из обрабатываемого текста. Универсального списка стоп-слов в исследовании nlp не существует, однако модуль nltk содержит список стоп-слов. "},{"metadata":{},"cell_type":"markdown","source":"Следующий используемый здесь пакет — это стемминг. Идея стемминга — это своего рода метод нормализации. Многие варианты слов несут одно и то же значение, кроме случаев, когда используется время. Итак, чтобы очистить пространство, мы используем метод стемминга, и один из используемых здесь пакетов — PorterStemmer. "},{"metadata":{"trusted":true},"cell_type":"code","source":"print(final_all.head(1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" Импортируем стоп-слова из nltk.corpus.\n  ##  NLTK - это аббревиатура от Natural Language Toolkit. \nУдаляет такие стоп-слова: the, is, and etc.."},{"metadata":{"trusted":true},"cell_type":"code","source":"pos_com_city_empType_jobDesc = final_all['pos_com_city_empType_jobDesc']\n\n#Удаление стоп-слов и применение PorterStemmer \n\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\nstemmer =  PorterStemmer()\nstop = stopwords.words('english')\nonly_text = pos_com_city_empType_jobDesc.apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\nonly_text.head()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Разбиение каждого слова на строку через пробел. "},{"metadata":{"trusted":true},"cell_type":"code","source":"only_text = only_text.apply(lambda x : filter(None,x.split(\" \")))\nprint(only_text.head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Здесь **стемминг** в основном используется для удаления суффиксов и общих слов, которые повторяются и разделяются запятыми. for y in x означает для каждого слова (y) в общем списке (x) "},{"metadata":{"trusted":true},"cell_type":"code","source":"only_text = only_text.apply(lambda x : [stemmer.stem(y) for y in x])\nprint(only_text.head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"В приведенном выше коде мы разделили каждую букву в слове через запятую, теперь на этом шаге мы соединяем слова (x) \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"only_text = only_text.apply(lambda x : \" \".join(x))\nprint(only_text.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Добавление избранного столбца обратно в pandas\n\nfinal_all['text']= only_text\n\n#Поскольку добавили новый столбец, выполнив все операции с использованием лямбда-функции, \n#удалим ненужный столбец \n\nfinal_all = final_all.drop(\"pos_com_city_empType_jobDesc\", 1)\n\nlist(final_all)\nfinal_all.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#сохранить этот файл для резервного копирования \n#final_all.to_csv(\"job_data.csv\", index=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# TF-IDF (Term Frequency - Inverse Document Frequency) \nЭтот метод также называется нормализацией.\nTF — сколько раз конкретное слово встречается в одном документе.\nIDF — уменьшает масштаб слов, которые часто встречаются в документах. "},{"metadata":{"trusted":true},"cell_type":"code","source":"#Инициализация tfidf векторизатора\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_extraction.text import CountVectorizer\n\ntfidf_vectorizer = TfidfVectorizer()\n\ntfidf_jobid = tfidf_vectorizer.fit_transform((final_all['text'])) #подгонка и преобразование вектора \ntfidf_jobid","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Корпус запросов пользователей\nВозьмём другой набор данных, который называется Job_Views"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Рассмотрим новый набор данных и примем во внимание наборов данных job_view \n#интересуют: должность, опыт кандидата для создания запроса, который подал заявку на работу\n\njob_view = pd.read_csv(\"../input/Job_Views.csv\")\njob_view.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(job_view.isnull(), cbar=False);","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"#Подмножество только необходимых столбцов, без учёта ненужных\n\njob_view = job_view[['Applicant.ID', 'Job.ID', 'Position', 'Company','City']]\n\njob_view[\"pos_com_city\"] = job_view[\"Position\"].map(str) + \"  \" + job_view[\"Company\"] +\"  \"+ job_view[\"City\"]\n\njob_view['pos_com_city'] = job_view['pos_com_city'].str.replace('[^a-zA-Z \\n\\.]',\"\")\n\njob_view['pos_com_city'] = job_view['pos_com_city'].str.lower()\n\njob_view = job_view[['Applicant.ID','pos_com_city']]\n\njob_view.head()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Experience\nВозьмём опыт всех соискателей, подавших заявки на вакансию, и сравниваем интересующие нас места с вакансиями, которые присутствовали в наших предыдущих данных. "},{"metadata":{"trusted":true},"cell_type":"code","source":"#Experience\nexper_applicant = pd.read_csv(\"../input/Experience.csv\")\nexper_applicant.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(exper_applicant.isnull(), cbar=False);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Возьмём только Position\n\nexper_applicant = exper_applicant[['Applicant.ID','Position.Name']]\n\n#Почистим текст\n\nexper_applicant['Position.Name'] = exper_applicant['Position.Name'].str.replace('[^a-zA-Z \\n\\.]',\"\")\n\nexper_applicant.head()\nlist(exper_applicant)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"exper_applicant['Position.Name'] = exper_applicant['Position.Name'].str.lower()\nexper_applicant.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"exper_applicant =  exper_applicant.sort_values(by='Applicant.ID')\nexper_applicant = exper_applicant.fillna(\" \")\nexper_applicant.head(20)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Для applicant_id 10001 описание должности отображается как Nan в первых трех строках, поэтому эти наблюдения будут удалены, и не будут учитываться в наборе данных."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Добавим одинаковые строки в одну\n\nexper_applicant = exper_applicant.groupby('Applicant.ID', sort=False)['Position.Name'].apply(' '.join).reset_index()\nexper_applicant.head(20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Position of Interest"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"#Position of interest\n\npoi =  pd.read_csv(\"../input/Positions_Of_Interest.csv\", sep=',')\npoi = poi.sort_values(by='Applicant.ID')\npoi.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(poi.isnull(), cbar=False);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Нет необходимости в создании и обновлении, т.к. \n# у нас нет дедлайна, поэтому отбросим ненужное\n\npoi = poi.drop('Updated.At', 1)\npoi = poi.drop('Created.At', 1)\n\n#Почистим текст\n\npoi['Position.Of.Interest'] = poi['Position.Of.Interest'].str.replace('[^a-zA-z \\n\\.]',\"\")\npoi['Position.Of.Interest'] = poi['Position.Of.Interest'].str.lower()\npoi = poi.fillna(\" \")\npoi.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"poi = poi.groupby('Applicant.ID', sort=True)['Position.Of.Interest'].apply(' '.join).reset_index()\npoi.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Слияние"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"#Сольём jobs и experience \n\nout_joint_jobs = job_view.merge(exper_applicant, left_on='Applicant.ID', right_on='Applicant.ID', how='outer')\nprint(out_joint_jobs.shape)\nout_joint_jobs = out_joint_jobs.fillna(' ')\nout_joint_jobs = out_joint_jobs.sort_values(by='Applicant.ID')\nout_joint_jobs.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Сольём position of interest с существующим датафреймом\n\njoint_poi_exper_view = out_joint_jobs.merge(poi, left_on='Applicant.ID', right_on='Applicant.ID', how='outer')\njoint_poi_exper_view = joint_poi_exper_view.fillna(' ')\njoint_poi_exper_view = joint_poi_exper_view.sort_values(by='Applicant.ID')\njoint_poi_exper_view.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Объединим все столбцы\n\njoint_poi_exper_view[\"pos_com_city1\"] = joint_poi_exper_view[\"pos_com_city\"].map(str) + joint_poi_exper_view[\"Position.Name\"] +\" \"+ joint_poi_exper_view[\"Position.Of.Interest\"]\n\njoint_poi_exper_view.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_poi_exper_view = joint_poi_exper_view[['Applicant.ID','pos_com_city1']]\nfinal_poi_exper_view.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_poi_exper_view.columns = ['Applicant_id','pos_com_city1']\nfinal_poi_exper_view.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_poi_exper_view = final_poi_exper_view.sort_values(by='Applicant_id')\nfinal_poi_exper_view.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_poi_exper_view['pos_com_city1'] = final_poi_exper_view['pos_com_city1'].str.replace('[^a-zA-Z \\n\\.]',\"\")\nfinal_poi_exper_view.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_poi_exper_view['pos_com_city1'] = final_poi_exper_view['pos_com_city1'].str.lower()\nfinal_poi_exper_view.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_poi_exper_view = final_poi_exper_view.reset_index(drop=True)\nfinal_poi_exper_view.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Возьмём рандомную строку"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Берём пользователя\nu = 6945\nindex = np.where(final_poi_exper_view['Applicant_id'] == u)[0][0]\nuser_q = final_poi_exper_view.iloc[[index]]\nuser_q","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Используем модель векторного пространства (косинусное подобие)\nhttps://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_similarity.html\n\n**Теория**\n\nНам нужно найти какое-то сходство между описанием должности и набором резюме. \nКосинусное сходство между выборками по X и Y: вычисляет подобие как нормализованное скалярное произведение X и Y:\n\n     K (X, Y) = <X, Y> / (|| X || * || Y ||)\nРезультатом является косинусное подобие, которое инвариантно к масштабированию и ограничивает значение от -1 до 1. Значение косинуса 0 означает, что два вектора расположены под углом 90 градусов друг к другу (ортогональны) и не имеют совпадений. Чем ближе значение косинуса к 1, тем меньше угол и больше совпадение между векторами. \nВ общем, cos θ указывает на подобие с точки зрения направления векторов. Это остается в силе по мере увеличения числа измерений, следовательно, cos θ является полезной мерой в многомерном пространстве. "},{"metadata":{"trusted":true},"cell_type":"code","source":"#Создание tf-idf запроса соискателя и вычисление его косинусного сходства с работой \n\nfrom sklearn.metrics.pairwise import cosine_similarity\nuser_tfidf = tfidf_vectorizer.transform(user_q['pos_com_city1'])\noutput = map(lambda x: cosine_similarity(user_tfidf, x),tfidf_jobid)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output2 = list(output)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Берём job id's из рекоммендаций\n\ntop = sorted(range(len(output2)), key=lambda i: output2[i], reverse=True)[:50]\nrecommendation = pd.DataFrame(columns = ['ApplicantID', 'JobID'])\n\ncount = 0\nfor i in top:\n    recommendation.at[count, 'ApplicantID'] = u\n    recommendation.at[count,'JobID'] = final_all['Job.ID'][i]\n    count += 1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"****Оценка косинусного сходства****"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"recommendation","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"#Получение job id's и их данных\n\nnearestjobs = recommendation['JobID']\njob_description = pd.DataFrame(columns = ['JobID','text'])\nfor i in nearestjobs:\n    index = np.where(final_all['Job.ID'] == i)[0][0]    \n    job_description.at[count, 'JobID'] = i\n    job_description.at[count, 'text'] = final_all['text'][index]\n    count += 1","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"#Выведем работу, соответствующую запросам\n\njob_description","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"job_description.to_csv(\"recommended_content.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_all.to_csv(\"job_data.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}